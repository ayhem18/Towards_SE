{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This is my attempt to solve the first assigment in the Information Retrieval course offered in Innopolis University"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from urllib.parse import urlparse\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "\n",
    "class Document:\n",
    "    no_url_msg = \"\\nAN URL MUST BE SET BEFORE PROCEEDING WITH A 'Document' OBJECT\\n\"\n",
    "\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "    def _extract_file_extension(self, url):\n",
    "        '''\n",
    "            Finding the extension of the file or the link\n",
    "        '''\n",
    "        parsed_url = urlparse(url)\n",
    "        path = parsed_url.path\n",
    "        if not path:\n",
    "            return \"html\"\n",
    "        _, ext = os.path.splitext(path)\n",
    "        return ext[1:] if ext else \"html\"\n",
    "\n",
    "\n",
    "    def __get_file_name(self):\n",
    "        if not self.url:\n",
    "            print(self.no_url_msg)\n",
    "            return None\n",
    "        \n",
    "        # first extract the hashed name\n",
    "        file_name = hashlib.md5(self.url.encode('utf-8')).hexdigest()\n",
    "        # add the extension\n",
    "        file_name += f'.{self._extract_file_extension(self.url) }'\n",
    "        # save the file\n",
    "        file_name = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "        return file_name\n",
    "\n",
    "    def get(self):\n",
    "        if not self.load():\n",
    "            if not self.download():\n",
    "                raise FileNotFoundError(self.url)\n",
    "            else:\n",
    "                self.persist()\n",
    "\n",
    "\n",
    "    def download(self):\n",
    "        if not self.url:\n",
    "            print(self.no_url_msg)\n",
    "            return False\n",
    "\n",
    "        r =  requests.get(url=self.url, allow_redirects=True)    \n",
    "        if r.status_code != 200:\n",
    "            print(f\"The status code recieved is {r.status_code}.Please make sure the url: {self.url}\\n is valid and you have the needed permissions\\n\")\n",
    "            return False\n",
    "        \n",
    "        self.content = r.content\n",
    "        return True\n",
    "    \n",
    "\n",
    "    def persist(self):\n",
    "        file_name = self.__get_file_name()\n",
    "        if file_name is None:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            with open(file_name, 'wb') as f: \n",
    "                f.write(self.content)\n",
    "            return True\n",
    "\n",
    "        except FileNotFoundError as ffe:\n",
    "            print(\"the file has not been yet created!!\")\n",
    "            return False\n",
    "\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        file_name = self.__get_file_name()\n",
    "        \n",
    "        if file_name is None:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            with open(file_name, 'rb') as f: \n",
    "                # set the file's content to the content field\n",
    "                self.content = f.read()\n",
    "            return True\n",
    "        \n",
    "        except FileNotFoundError as ffe:\n",
    "            # print(\"the file has not been yet created!!\")\n",
    "            return False\n",
    "\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document('http://sprotasov.ru/data/iu.txt')\n",
    "\n",
    "doc.get()\n",
    "assert doc.content, \"Document download failed\"\n",
    "assert \"Code snippets, demos and labs for the course\" in str(doc.content), \"Document content error\"\n",
    "\n",
    "doc.get()\n",
    "assert doc.load(), \"Load should return true for saved document\"\n",
    "assert \"Code snippets, demos and labs for the course\" in str(doc.content), \"Document load from disk error\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4.element import Comment\n",
    "import urllib.parse\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "import html5lib\n",
    "\n",
    "class HtmlDocument(Document):\n",
    "    def __init__(self, url, text_join_str=' '):\n",
    "        super().__init__(url)\n",
    "        # this character is used to join all the pieces of visible text scapped from the site \n",
    "        self.text_join_str = text_join_str\n",
    "\n",
    "    def _is_html(self):\n",
    "        # this function determines whether the parsed document is html of xml\n",
    "        try:\n",
    "            p = html5lib.HTMLParser()\n",
    "            p.parse(self.content)   \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "\n",
    "    def parse(self):\n",
    "        # this function assumes the self.content is already set\n",
    "        if self.content is None:\n",
    "            print(\"Please make sure to have the 'content' field set\")        \n",
    "            return\n",
    "                \n",
    "        # create the soup object to parse the html document\n",
    "        doc_soup = bs(self.content, 'html.parser' if self._is_html() else 'lxml')\n",
    "\n",
    "        # extract anchors\n",
    "        self.anchors = [(str(link.text) if link is not None else '', \n",
    "        urljoin(self.url, link['href'])) for link in doc_soup.find_all('a', href=True)] # filter those anchors with no actual link associated with them\n",
    "        \n",
    "        # extract images\n",
    "        self.images = [urljoin(self.url, img['src']) for img in doc_soup.find_all('img', src=True)] # filter the anchors with no actual image associated with them.\n",
    "        \n",
    "        # extract text \n",
    "        # firstly extract all text\n",
    "        raw_text = doc_soup.findAll(string=True)\n",
    "        # secondly filter the text associated with unwanted tags\n",
    "        def plain_text(element):\n",
    "            return  element.parent.name not in ['style', 'script', 'title', 'head', 'meta', '[document]'] and not isinstance(element, Comment) \n",
    "\n",
    "        filtered_text = filter(plain_text, raw_text) # remove unwanted text\n",
    "        # join all the text into a single text by the text_join_char attribute\n",
    "        self.text = re.sub(r\"\\s+\", ' ',self.text_join_str.join([t.strip() for t in filtered_text if t.strip()]))\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = HtmlDocument(\"http://sprotasov.ru\")\n",
    "doc.get()\n",
    "doc.parse()\n",
    "\n",
    "\n",
    "# print(doc.anchors)\n",
    "# print(doc.images)\n",
    "# print(doc.text)\n",
    "\n",
    "assert \"http://sprotasov.ru/images/gb.svg\" in doc.images, \"Error parsing images\"\n",
    "assert any(p[1] == \"https://twitter.com/07C3\" for p in doc.anchors), \"Error parsing links\"\n",
    "assert \"just few links\" in doc.text, \"Error parsing text\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: spacy in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (8.1.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Requirement already satisfied: langdetect in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (1.0.7)\n",
      "Requirement already satisfied: six in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: langcodes in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: language_data in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: marisa-trie<0.8.0,>=0.7.7 in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from language_data) (0.7.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (from marisa-trie<0.8.0,>=0.7.7->language_data) (58.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk \n",
    "! pip install spacy\n",
    "! pip install langdetect\n",
    "! pip install langcodes\n",
    "! pip install language_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bouab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bouab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the data needed for nltk\n",
    "import nltk\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_languages = [\"german\", 'spanish', 'english', 'russian', 'chinese', 'arabic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use some simple NLP tools here\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize \n",
    "from langdetect import detect\n",
    "from collections import Counter\n",
    "from langcodes import Language\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "punc_regex = r'.*[!\\\"#\\$%&\\'\\(\\)\\*\\+,\\.:;<=>\\?@\\[\\\\\\]\\^_`{\\|}~«»]+.*'\n",
    "\n",
    "class HtmlDocumentTextData:\n",
    "    \n",
    "    def __init__(self, url):        \n",
    "        self.doc = HtmlDocument(url)\n",
    "        self.doc.get()\n",
    "        self.doc.parse()\n",
    "    \n",
    "    def _detect_language(self):\n",
    "        # to use the power of NLP tools, regardless of the text's language, language detection is needed\n",
    "        text = self.doc.text\n",
    "        # determine the language used in the text\n",
    "        lan_code = detect(text)\n",
    "        # the language variable represents the code of the language and not its standard form\n",
    "        # the langcodes package is in for the rescue\n",
    "        language = Language.make(language=lan_code).display_name().lower()\n",
    "        if language not in used_languages: \n",
    "            return None\n",
    "        return language, set(stopwords.words(language))        \n",
    "\n",
    "    def get_sentences(self):\n",
    "        text = self.doc.text\n",
    "        lang, _ = self._detect_language()\n",
    "        # the main limitation of this class is that it assumes the text's language is english\n",
    "        result = sent_tokenize(text, language=lang)\n",
    "        return result\n",
    "    \n",
    "    def get_word_stats(self):\n",
    "        \n",
    "        text = self.doc.text\n",
    "        lang = self._detect_language()\n",
    "        words = []\n",
    "\n",
    "        if lang is not None:\n",
    "            lang, stop_words = lang            \n",
    "            try:\n",
    "                # remove any stop words (also known as filler words as well as any \"words\" containing punctuation marks)\n",
    "                words = [w.lower().strip() for w in word_tokenize(text, language=lang) if w.lower().strip() not in stop_words and re.match(punc_regex, w.lower().strip()) is None]\n",
    "            except Exception as e:\n",
    "                pass  \n",
    "        \n",
    "        # create the counter and map each word to its frequency\n",
    "        counter = Counter()\n",
    "        for w in words:\n",
    "            counter[w] += 1 \n",
    "        return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('иннополис', 20), ('университет', 11), ('университета', 11), ('центр', 10), ('образование', 8), ('робототехники', 6), ('деятельность', 6), ('управления', 5), ('образовательной', 5), ('2022', 5)]\n"
     ]
    }
   ],
   "source": [
    "doc = HtmlDocumentTextData(\"https://innopolis.university/\")\n",
    "\n",
    "print(doc.get_word_stats().most_common(10))\n",
    "assert [x for x in doc.get_word_stats().most_common(10) if x[0] == 'иннополис'], 'иннополис should be among most common'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import RequestException \n",
    "\n",
    "\n",
    "class Crawler:\n",
    "    def crawl_generator(self, source, depth=1):\n",
    "        # the minimum value of depth is '1'\n",
    "        depth = max(1, depth)\n",
    "\n",
    "        try:            \n",
    "            top_doc = HtmlDocumentTextData(source)\n",
    "            yield  (top_doc, top_doc.doc.url)\n",
    "\n",
    "            if depth > 1: \n",
    "                for link in top_doc.doc.anchors:\n",
    "                    for value in self.crawl_generator(link[1], depth=depth - 1):\n",
    "                        yield value\n",
    "\n",
    "        except RequestException as reqe:\n",
    "            print(f\"the url: {source} is not valid\")\n",
    "            print(reqe)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://innopolis.university/en/\n",
      "283 distinct word(s) so far\n",
      "https://innopolis.university/\n",
      "795 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "795 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "795 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "795 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "795 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "795 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "795 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "795 distinct word(s) so far\n",
      "https://apply.innopolis.university/en\n",
      "1393 distinct word(s) so far\n",
      "The status code recieved is 404.Please make sure the url: https://innopolis.university/proekty/activity/en\"\n",
      " is valid and you have the needed permissions\n",
      "\n",
      "https://media.innopolis.university/en\n",
      "1457 distinct word(s) so far\n",
      "https://innopolis.university/lk/\n",
      "1467 distinct word(s) so far\n",
      "https://innopolis.university/en/about/\n",
      "1643 distinct word(s) so far\n",
      "https://innopolis.university/en/board/\n",
      "1720 distinct word(s) so far\n",
      "https://innopolis.university/en/team/\n",
      "1721 distinct word(s) so far\n",
      "https://innopolis.university/en/team-structure/\n",
      "1724 distinct word(s) so far\n",
      "https://innopolis.university/en/team-structure/education-academics/\n",
      "1726 distinct word(s) so far\n",
      "https://innopolis.university/en/team-structure/techcenters/\n",
      "1730 distinct word(s) so far\n",
      "https://innopolis.university/en/faculty/\n",
      "2577 distinct word(s) so far\n",
      "https://innopolis.university/en/faculty/\n",
      "2577 distinct word(s) so far\n",
      "https://career.innopolis.university/en/job/\n",
      "3078 distinct word(s) so far\n",
      "https://career.innopolis.university/en/\n",
      "3179 distinct word(s) so far\n",
      "https://innopolis.university/en/campus\n",
      "3292 distinct word(s) so far\n",
      "https://innopolis.university/en/contacts/\n",
      "3296 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/\n",
      "3296 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "3296 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/bachelor/\n",
      "3358 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/master/\n",
      "3376 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/postgraduate-study/\n",
      "3407 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/stud-life/\n",
      "3470 distinct word(s) so far\n",
      "https://innopolis.university/en/international-relations-office/\n",
      "3691 distinct word(s) so far\n",
      "https://innopolis.university/en/incomingstudents/\n",
      "4060 distinct word(s) so far\n",
      "https://innopolis.university/en/outgoingstudents/\n",
      "4373 distinct word(s) so far\n",
      "https://innopolis.university/en/teachingexcellencecenter/\n",
      "4554 distinct word(s) so far\n",
      "https://innopolis.university/en/writinghubhome/\n",
      "4567 distinct word(s) so far\n",
      "https://alumni.innopolis.university/\n",
      "4722 distinct word(s) so far\n",
      "https://innopolis.university/en/research/\n",
      "4748 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "4748 distinct word(s) so far\n",
      "https://innopolis.university/en/team-structure/team-faculty/\n",
      "4759 distinct word(s) so far\n",
      "https://innopolis.university/en/team-structure/team-faculty2/\n",
      "4768 distinct word(s) so far\n",
      "https://innopolis.university/en/nir2022/\n",
      "4930 distinct word(s) so far\n",
      "https://innopolis.university/en/proekty/activity/\n",
      "4964 distinct word(s) so far\n",
      "https://innopolis.university/en/team-structure/techcenters/\n",
      "4964 distinct word(s) so far\n",
      "https://innopolis.university/en/startupstudio/\n",
      "4997 distinct word(s) so far\n",
      "https://innopolis.university/en/internationalpartners/\n",
      "5066 distinct word(s) so far\n",
      "https://innopolis.university/en/organizatsiya-i-provedenie-meropriyatiy/\n",
      "5155 distinct word(s) so far\n",
      "https://innopolis.university/en/?special=Y\n",
      "5165 distinct word(s) so far\n",
      "https://innopolis.university/search/\n",
      "5168 distinct word(s) so far\n",
      "https://innopolis.university/\n",
      "5168 distinct word(s) so far\n",
      "https://innopolis.university/lk/\n",
      "5168 distinct word(s) so far\n",
      "https://innopolis.university/search/\n",
      "5168 distinct word(s) so far\n",
      "https://innopolis.university/\n",
      "5168 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/\n",
      "5168 distinct word(s) so far\n",
      "https://innopolis.university/en/ido/\n",
      "5193 distinct word(s) so far\n",
      "https://dovuz.innopolis.university/\n",
      "5354 distinct word(s) so far\n",
      "https://career.innopolis.university/en/\n",
      "5354 distinct word(s) so far\n",
      "the url: https://university.innopolis.ru/en/about/ is not valid\n",
      "HTTPSConnectionPool(host='university.innopolis.ru', port=443): Max retries exceeded with url: /en/about/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)')))\n",
      "https://apply.innopolis.university/en/bachelor/\n",
      "5354 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/master/\n",
      "5354 distinct word(s) so far\n",
      "https://apply.innopolis.university/en/postgraduate-study/\n",
      "5354 distinct word(s) so far\n",
      "The status code recieved is 403.Please make sure the url: http://www.campuslife.innopolis.ru\n",
      " is valid and you have the needed permissions\n",
      "\n",
      "https://innopolis.university/en/international-relations-office/\n",
      "5354 distinct word(s) so far\n",
      "https://innopolis.university/en/research/\n",
      "5354 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "5354 distinct word(s) so far\n",
      "https://media.innopolis.university/news/webinar-interstudents-eng/\n",
      "5413 distinct word(s) so far\n",
      "https://media.innopolis.university/news/webinar-interstudents-eng/\n",
      "5413 distinct word(s) so far\n",
      "https://media.innopolis.university/news/devops-summer-school/\n",
      "5547 distinct word(s) so far\n",
      "https://media.innopolis.university/news/webinar-for-international-candidates-/\n",
      "5557 distinct word(s) so far\n",
      "https://media.innopolis.university/news/registration-innopolis-open-2020/\n",
      "5642 distinct word(s) so far\n",
      "https://media.innopolis.university/news/cyber-resilience-petrenko/\n",
      "5805 distinct word(s) so far\n",
      "https://media.innopolis.university/news/innopolis-university-extends-international-application-deadline-/\n",
      "5816 distinct word(s) so far\n",
      "https://media.innopolis.university/news/self-driven-school/\n",
      "5883 distinct word(s) so far\n",
      "https://media.innopolis.university/en/\n",
      "5883 distinct word(s) so far\n",
      "the url: tel:+7 (843) 203-92-53 is not valid\n",
      "No connection adapters were found for 'tel:+7 (843) 203-92-53'\n",
      "The status code recieved is 404.Please make sure the url: https://innopolis.university/en/university@innopolis.ru\n",
      " is valid and you have the needed permissions\n",
      "\n",
      "https://innopolis.university/en/form/\n",
      "5945 distinct word(s) so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://innopolis.university/public/files/Consent_to_the_processing_of_PD_for_UI.pdf\n",
      "Skipping https://innopolis.university/public/files/Consent_to_the_processing_of_PD_for_UI.pdf\n",
      "https://t.me/universityinnopolis\n",
      "5952 distinct word(s) so far\n",
      "https://vk.com/innopolisu\n",
      "6108 distinct word(s) so far\n",
      "https://www.youtube.com/user/InnopolisU\n",
      "6121 distinct word(s) so far\n",
      "https://apply.innopolis.ru/en/\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/proekty/activity/\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/about/\n",
      "7663 distinct word(s) so far\n",
      "https://career.innopolis.university/en/\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "7663 distinct word(s) so far\n",
      "the url: mailto:319@innopolis.ru is not valid\n",
      "No connection adapters were found for 'mailto:319@innopolis.ru'\n",
      "https://panoroo.com/virtual-tours/NvQZM6B2\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/contacts/\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "7663 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "7663 distinct word(s) so far\n",
      "https://media.innopolis.university/en/news/\n",
      "7663 distinct word(s) so far\n",
      "https://media.innopolis.university/en/events/\n",
      "7665 distinct word(s) so far\n",
      "https://innopolis.university/en/\n",
      "7665 distinct word(s) so far\n",
      "the url: http://www.minsvyaz.ru/en/ is not valid\n",
      "HTTPConnectionPool(host='www.minsvyaz.ru', port=80): Max retries exceeded with url: /en/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FEEC6E36D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://minobrnauki.gov.ru/\n",
      "7875 distinct word(s) so far\n",
      "https://career.innopolis.university/konkursnyezayavkiprofessorskoprepodavatelskogosostava/\n",
      "7904 distinct word(s) so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://innopolis.university/public/files/Consent_to_the_processing_of_PD_for_UI.pdf\n",
      "Skipping https://innopolis.university/public/files/Consent_to_the_processing_of_PD_for_UI.pdf\n",
      "Done\n",
      "[('university', 1949), ('innopolis', 1057), ('education', 796), ('research', 773), ('international', 585), ('students', 574), ('development', 464), ('•', 444), ('russia', 423), ('science', 401), ('-', 398), ('russian', 384), ('faculty', 375), ('program', 373), ('robotics', 369), ('иннополис', 329), ('student', 327), ('information', 301), ('teaching', 283), ('activities', 272)]\n"
     ]
    }
   ],
   "source": [
    "crawler = Crawler()\n",
    "counter = Counter()\n",
    "\n",
    "for c2 in crawler.crawl_generator(\"https://innopolis.university/en/\", 2):\n",
    "    c = c2[0]\n",
    "    print(c.doc.url)\n",
    "    if c.doc.url[-4:] in ('.pdf', '.mp3', '.avi', '.mp4', '.txt'):\n",
    "        print(\"Skipping\", c.doc.url)\n",
    "        continue\n",
    "    counter.update(c.get_word_stats())\n",
    "    print(len(counter), \"distinct word(s) so far\")\n",
    "    \n",
    "print(\"Done\")\n",
    "\n",
    "print(counter.most_common(20))\n",
    "assert [x for x in counter.most_common(20) if x[0] == 'innopolis'], 'innopolis sould be among most common'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('se_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87916a9df29343f518d363a6149a1dfa14832b884faad311882187c1f88054e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
