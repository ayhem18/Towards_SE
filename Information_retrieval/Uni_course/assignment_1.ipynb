{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This is my attempt to solve the first assigment in the Information Retrieval course offered in Innopolis University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def wget(url, file_name=None):\n",
    "    # allow redirects\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    # only proceed if the status code is 200\n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code, response.reason, 'for', url)\n",
    "        print(\"EXITING...\")\n",
    "        return None\n",
    "    \n",
    "    # if the file name wasn't given, infer it from the url\n",
    "    if file_name is None:\n",
    "        # let's consider \n",
    "        url_name_regex = r'^https?.*\\/([^\\/?#]*)[\\?#]?'\n",
    "        match_url = re.search(url_name_regex, url)\n",
    "        file_name = match_url.group(1)\n",
    "        # the file will be saved in the program's directory\n",
    "        file_name = os.path.join(os.getcwd(), file_name)\n",
    "        if not file_name:\n",
    "            raise NameError(f'File name was neither given as an argument not could be inferred from {url}')\n",
    "        \n",
    "    # if two urls had the same file name, the second one would be rejected\n",
    "    if os.path.exists(file_name):\n",
    "        raise OSError(f'File {file_name} already exists!!!')\n",
    "    \n",
    "    # write the content of the url to a local file\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f'File saved as {file_name}')\n",
    "    \n",
    "    return file_name\n",
    "\n",
    "\n",
    "if __name__ == 'main':\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a crawler...\n",
    "import requests \n",
    "from urllib.parse import quote\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "class Document:\n",
    "    no_url_msg = \"\\nAN URL MUST BE SET BEFORE PROCEEDING WITH A 'DOCUMENT' OBJECT\\n\"\n",
    "\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "    def __get_file_name(self):\n",
    "        if not self.url:\n",
    "            print(self.no_url_msg)\n",
    "            return None\n",
    "        \n",
    "        # first extract the hashed name\n",
    "        file_name = hashlib.md5(self.url.encode('utf-8')).hexdigest()\n",
    "        # save the file in the current directory\n",
    "        file_name = os.path.join(os.getcwd(), f'{file_name}.txt')\n",
    "\n",
    "        return file_name\n",
    "\n",
    "    def get(self):\n",
    "        if not self.load():\n",
    "            if not self.download():\n",
    "                raise FileNotFoundError(self.url)\n",
    "            else:\n",
    "                self.persist()\n",
    "\n",
    "\n",
    "    def download(self):\n",
    "        if not self.url:\n",
    "            print(self.no_url_msg)\n",
    "            return False\n",
    "\n",
    "        r =  requests.get(url=self.url, allow_redirects=True)\n",
    "        if r.status_code != 200:\n",
    "            print(\"the connection was not successful.\")\n",
    "            return False\n",
    "        \n",
    "        self.content = r.content\n",
    "        return True\n",
    "    \n",
    "\n",
    "    def persist(self):\n",
    "        file_name = self.__get_file_name()\n",
    "        if file_name is None:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            with open(file_name, 'wb') as f: \n",
    "                f.write(self.content)\n",
    "            return True\n",
    "\n",
    "        except FileNotFoundError as ffe:\n",
    "            print(\"the file has not been yet created!!\")\n",
    "            return False\n",
    "\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        file_name = self.__get_file_name()\n",
    "        if file_name is None:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            with open(file_name, 'rb') as f: \n",
    "                # set the file's content to the content field\n",
    "                self.content = f.read()\n",
    "            return True\n",
    "        \n",
    "        except FileNotFoundError as ffe:\n",
    "            print(\"the file has not been yet created!!\")\n",
    "            return False\n",
    "\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the file has not been yet created!!\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "doc = Document('http://sprotasov.ru/data/iu.txt')\n",
    "\n",
    "doc.get()\n",
    "assert doc.content, \"Document download failed\"\n",
    "assert \"Code snippets, demos and labs for the course\" in str(doc.content), \"Document content error\"\n",
    "\n",
    "doc.get()\n",
    "assert doc.load(), \"Load should return true for saved document\"\n",
    "print('3')\n",
    "assert \"Code snippets, demos and labs for the course\" in str(doc.content), \"Document load from disk error\"\n",
    "print('4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "class HtmlDocument(Document):\n",
    "    \n",
    "    def parse(self):\n",
    "        #TODO extract plain text, images and links from the document\n",
    "        self.anchors = [(\"fake link text\", \"http://fake.url/\")]\n",
    "        self.images = [\"http://image.com/fake.jpg\"]\n",
    "        self.text = \"fake text and some other text\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('se_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87916a9df29343f518d363a6149a1dfa14832b884faad311882187c1f88054e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
