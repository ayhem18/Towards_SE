{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This is my attempt to solve the first assigment in the Information Retrieval course offered in Innopolis University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def wget(url, file_name=None):\n",
    "    # allow redirects\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    # only proceed if the status code is 200\n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code, response.reason, 'for', url)\n",
    "        print(\"EXITING...\")\n",
    "        return \n",
    "    \n",
    "    # if the file name wasn't given, infer it from the url\n",
    "    if file_name is None:\n",
    "        # let's consider \n",
    "        url_name_regex = r'^https?.*\\/([^\\/?#]*)[\\?#]?'\n",
    "        match_url = re.search(url_name_regex, url)\n",
    "        file_name = match_url.group(1)\n",
    "        # the file will be saved in the program's directory\n",
    "        file_name = os.path.join(os.getcwd(), file_name)\n",
    "        if not file_name:\n",
    "            raise NameError(f'File name was neither given as an argument not could be inferred from {url}')\n",
    "        \n",
    "    # if two urls had the same file name, the second one would be rejected\n",
    "    if os.path.exists(file_name):\n",
    "        raise OSError(f'File {file_name} already exists!!!')\n",
    "    \n",
    "    # write the content of the url to a local file\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f'File saved as {file_name}')\n",
    "    \n",
    "if __name__ == 'main':\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a crawler...\n",
    "import requests \n",
    "from urllib.parse import quote\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "    \n",
    "    def get(self):\n",
    "        if not self.load():\n",
    "            if not self.download():\n",
    "                raise FileNotFoundError(self.url)\n",
    "        else:\n",
    "            self.persist()\n",
    "\n",
    "\n",
    "    def download(self):\n",
    "        # \n",
    "        pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('se_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87916a9df29343f518d363a6149a1dfa14832b884faad311882187c1f88054e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
