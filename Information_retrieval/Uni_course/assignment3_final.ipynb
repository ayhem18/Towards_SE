{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sugges_\n",
    "\n",
    "One of the strategies to improve user experience is to provide user with hints, or, otherwise, to autocomplete his queries. Let's consider suggest.\n",
    "\n",
    "Today we will practice generating suggestions using [Trie](https://en.wikipedia.org/wiki/Trie) data structure (prefix tree), see the example below.\n",
    "\n",
    "Plan of your homework:\n",
    "\n",
    "1. Build Trie based on real search query data, provided by AOL company;\n",
    "2. Generate suggestion based on a trie;\n",
    "3. Measure suggestion speed;\n",
    "\n",
    "![image](https://www.ritambhara.in/wp-content/uploads/2017/05/Screen-Shot-2017-05-01-at-4.01.38-PM.png)\n",
    "\n",
    "## 0. Install Trie data structure support\n",
    "\n",
    "You are free to use any library implementation of Trie, as well as the one we suggest (read the docs before asking any questions!): https://github.com/google/pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygtrie in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (2.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pygtrie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a trie upon a dataset\n",
    "\n",
    "### 1.1. [5] Read the dataset\n",
    "\n",
    "Download the [dataset](https://github.com/IUCVLab/information-retrieval/tree/main/datasets/aol) (we provide only the first part of the original data for simplicity (~3.5 mln queries)).\n",
    "\n",
    "Explore the data, see readme file. Load the dataset. Pass the assert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after downloading the data, and unzipping it\n",
    "import pandas as pd\n",
    "data_file_name = 'user-ct-test-collection-01.txt'\n",
    "# let's convert it to a tsv file \n",
    "\n",
    "with open(data_file_name, 'r') as r:\n",
    "    with open('dataset.tsv', 'w') as w:\n",
    "        w.write(r.read())\n",
    "\n",
    "\n",
    "aol_data = pd.read_csv('dataset.tsv',sep='\\t') \n",
    "\n",
    "assert aol_data.shape[0] == 3558411, \"Dataset size does not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>time</th>\n",
       "      <th>rank</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>142</td>\n",
       "      <td>westchester.gov</td>\n",
       "      <td>2006-03-20 03:55:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.westchestergov.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>142</td>\n",
       "      <td>207 ad2d 530</td>\n",
       "      <td>2006-04-08 01:31:14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.courts.state.ny.us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>142</td>\n",
       "      <td>vera.org</td>\n",
       "      <td>2006-04-08 08:38:42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.vera.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>217</td>\n",
       "      <td>lottery</td>\n",
       "      <td>2006-03-01 11:58:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.calottery.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>217</td>\n",
       "      <td>lottery</td>\n",
       "      <td>2006-03-01 11:58:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.calottery.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>217</td>\n",
       "      <td>ameriprise.com</td>\n",
       "      <td>2006-03-01 14:06:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.ameriprise.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>217</td>\n",
       "      <td>mizuno.com</td>\n",
       "      <td>2006-03-07 22:41:17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.mizuno.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>217</td>\n",
       "      <td>asiansexygoddess.com</td>\n",
       "      <td>2006-03-16 14:31:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.asiansexygoddess.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>217</td>\n",
       "      <td>bestasiancompany.com</td>\n",
       "      <td>2006-03-20 15:15:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.bestasiancompany.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>217</td>\n",
       "      <td>lottery</td>\n",
       "      <td>2006-03-27 14:10:38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.calottery.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                 query                 time  rank  \\\n",
       "6   142       westchester.gov  2006-03-20 03:55:57   1.0   \n",
       "14  142          207 ad2d 530  2006-04-08 01:31:14   1.0   \n",
       "17  142              vera.org  2006-04-08 08:38:42   1.0   \n",
       "27  217               lottery  2006-03-01 11:58:51   1.0   \n",
       "28  217               lottery  2006-03-01 11:58:51   1.0   \n",
       "29  217        ameriprise.com  2006-03-01 14:06:23   1.0   \n",
       "32  217            mizuno.com  2006-03-07 22:41:17   1.0   \n",
       "35  217  asiansexygoddess.com  2006-03-16 14:31:36   1.0   \n",
       "37  217  bestasiancompany.com  2006-03-20 15:15:43   1.0   \n",
       "38  217               lottery  2006-03-27 14:10:38   1.0   \n",
       "\n",
       "                                url  \n",
       "6     http://www.westchestergov.com  \n",
       "14    http://www.courts.state.ny.us  \n",
       "17              http://www.vera.org  \n",
       "27         http://www.calottery.com  \n",
       "28         http://www.calottery.com  \n",
       "29        http://www.ameriprise.com  \n",
       "32            http://www.mizuno.com  \n",
       "35  http://www.asiansexygoddess.com  \n",
       "37  http://www.bestasiancompany.com  \n",
       "38         http://www.calottery.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aol_data.columns = ['id', 'query', 'time', 'rank', 'url']\n",
    "aol_data[~aol_data['rank'].isna()].head(10)\n",
    "\n",
    "# the data is loaded correctly.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. [10] Build a Trie\n",
    "\n",
    "We want a suggest function to be **non-sensitive to stop words** because we don't want to upset the users if they confuses/omits prepositions. Consider *\"public events in Innopolis\"* vs *\"public events at Innopolis\"* or *\"public events Innopolis\"* - they all mean the same.\n",
    "\n",
    "Build a Trie based on the dataset, **storing query statistics such as query _frequency_, urls and ranks in the nodes**. Some queries may have no associated urls, others may have multiple ranked urls. Think of the way to store this information.\n",
    "\n",
    "Pass the asserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygtrie\n",
    "aol_trie = pygtrie.CharTrie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am my place. he roof\n"
     ]
    }
   ],
   "source": [
    "# each query should be associated with urls, ranks of these urls and also the frequency\n",
    "stops = set('a on at of to is from for and with using the in &'.split())\n",
    "\n",
    "# we will remove the stop words from our representations of the queries\n",
    "import re\n",
    "\n",
    "def process_query(query: str):\n",
    "    return \" \".join([x for x in re.split(r'\\s+', query.lower().strip()) if x not in stops])\n",
    "\n",
    "print(process_query('I am at my place. He is on the roof'))\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "class QueryNode:\n",
    "    # this class represents a query in the trie\n",
    "    # it stores all the necessary information about the query\n",
    "    def __init__(self, query):\n",
    "        # save the query\n",
    "        self.query = query\n",
    "        self.freq = 0\n",
    "        # the urls associated with the queries\n",
    "        self.urls = []\n",
    "        # the ranks of each of the urls\n",
    "        self.ranks = []\n",
    "    \n",
    "    def add_url(self, url, rank):\n",
    "        # first add the url to the list\n",
    "        self.urls.append(url)\n",
    "        self.ranks.append(rank)\n",
    "        self.freq += 1\n",
    "    \n",
    "    def best_url(self):\n",
    "        # returns the url with the highest rank\n",
    "        return self.urls[np.argmin(self.ranks)] # return the url with the highest rank\n",
    "    \n",
    "class QueryTrieNode:\n",
    "    # each concrete query should be associated with a reduced processed version\n",
    "    # all the trie should store the corrected ones (without stop words mainly)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.queries = []\n",
    "        self.queries_dict = {}\n",
    "\n",
    "    def add_query(self, original_query, url:str, rank:float):\n",
    "\n",
    "        if original_query in self.queries_dict:\n",
    "            # extract the index to access directly\n",
    "            index_query = self.queries_dict[original_query]\n",
    "            self.queries[index_query].add_url(url, rank)\n",
    "            return \n",
    "        # if this case the query was seen for the 1st time\n",
    "        self.queries_dict[original_query] = len(self.queries)\n",
    "        # add it to the queries                     \n",
    "        self.queries.append(QueryNode(original_query))\n",
    "        # add the url and the rank to the last query\n",
    "        self.queries[-1].add_url(url, rank)\n",
    "    @property\n",
    "    def urls(self):\n",
    "        all_urls = [q.urls for q in self.queries]\n",
    "        return list(itertools.chain(*all_urls))\n",
    "\n",
    "# create a function to add a query to the trie data structure\n",
    "\n",
    "\n",
    "def add_query_to_trie(row: str, trie:pygtrie=None):\n",
    "    if trie is None:\n",
    "        trie = aol_trie\n",
    "    # extract the original query\n",
    "    original_query = row['query']\n",
    "    # the original query might be null \n",
    "    if isinstance(original_query, str):\n",
    "        # process it\n",
    "        query = process_query(original_query)\n",
    "        if trie.has_node(query) != pygtrie.Trie.HAS_VALUE:\n",
    "            trie[query] = QueryTrieNode()\n",
    "        trie[query].add_query(original_query, row['url'], row['rank'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tree to avoid building it on multiple occasions\n",
    "import pickle\n",
    "aol_trie\n",
    "\n",
    "# file to pickle the trie instead of building it with every run\n",
    "file_name = 'aol_trie.pkl'\n",
    "\n",
    "\n",
    "# with open(file_name, 'wb') as file:\n",
    "#     pickle.dump(aol_trie, file)\n",
    "#     print(f'Object successfully saved to \"{file_name}\"')\n",
    "\n",
    "import os\n",
    "if os.path.exists(file_name):\n",
    "    # loading the trie\n",
    "    with open(file_name, 'rb') as f:\n",
    "        aol_trie = pickle.load(f)\n",
    "else:\n",
    "    # build the trie by applyinh the add_query_to_trie function\n",
    "    # to each row in the dataset\n",
    "    aol_data.apply(add_query_to_trie,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample question surveys ~ <__main__.QueryTrieNode object at 0x0000019E770218B0>\n",
      "sample questions immigration interview ~ <__main__.QueryTrieNode object at 0x0000019E77021970>\n",
      "sample questions interview ~ <__main__.QueryTrieNode object at 0x0000019E77021A30>\n",
      "sample questions family interview ~ <__main__.QueryTrieNode object at 0x0000019E77021AF0>\n",
      "sample questions sociology race ethnicity ~ <__main__.QueryTrieNode object at 0x0000019E77021BB0>\n",
      "sample questions biology ~ <__main__.QueryTrieNode object at 0x0000019E77021C70>\n",
      "sample questions us citizenship test ~ <__main__.QueryTrieNode object at 0x0000019E77021D30>\n",
      "sample questionarie teaching evaluation ~ <__main__.QueryTrieNode object at 0x0000019E77021DF0>\n",
      "sample questionnaire teaching evaluation ~ <__main__.QueryTrieNode object at 0x0000019E77021EB0>\n",
      "sample questionnaire clinical research coordinators certification ~ <__main__.QueryTrieNode object at 0x0000019E77021F70>\n"
     ]
    }
   ],
   "source": [
    "# test trie\n",
    "bag = []\n",
    "for key, val in aol_trie.iteritems(\"sample q\"):\n",
    "    print(key, '~', val)\n",
    "    \n",
    "    #NB: here we assume you store urls in a property of list type. But you can do something different. \n",
    "    bag += val.urls\n",
    "    \n",
    "    assert \"sample question\" in key, \"All examples have `sample question` substring\"\n",
    "    assert key[:len(\"sample question\")] == \"sample question\", \"All examples have `sample question` starting string\"\n",
    "\n",
    "for url in [\"http://www.surveyconnect.com\", \"http://www.custominsight.com\", \n",
    "            \"http://jobsearchtech.about.com\", \"http://www.troy.k12.ny.us\",\n",
    "            \"http://www.flinders.edu.au\", \"http://uscis.gov\"]:\n",
    "    assert url in bag, \"This url should be in a try\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [15] Write a suggest function which is non-sensitive to stop words\n",
    "\n",
    "Suggest options for user query based on Trie you just built.\n",
    "Output results sorted by frequency, print query count for each suggestion. If there is an url available, print the url too. If multiple url-s are available, print the one with the highest rank (the less the better).\n",
    "\n",
    "Pass the asserts.\n",
    "\n",
    "Question for analysis: What is the empirical threshold for minimal prefix for suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_user_query(query: str, trie, top_k=5, print_urls:bool=False) -> list[str]:\n",
    "    # first make sure to extract the processed request\n",
    "    p_query = process_query(query.strip().lower())\n",
    "\n",
    "    # firt check if the shortened version of the query was seen before\n",
    "    if not trie.has_subtrie(p_query):\n",
    "        return []\n",
    "\n",
    "    # the query given might not represent a complete query so we need to extract any query from our database that might correspond to user's input\n",
    "    possible_queries = [val.queries for _, val in trie.iteritems(p_query)]            \n",
    "    # flatten it\n",
    "    possible_queries = itertools.chain(*possible_queries)\n",
    "    # sort by frequency\n",
    "    possible_queries = sorted(possible_queries, key=lambda x : x.freq, reverse=True)\n",
    "\n",
    "    result = [pq.query for pq in possible_queries[:top_k]] \n",
    "\n",
    "    # display the best url for the top_k queries\n",
    "    if print_urls:\n",
    "        for pq in possible_queries[:top_k]:\n",
    "            best_url = pq.best_url()\n",
    "            if isinstance(best_url, str):\n",
    "                print(best_url)\n",
    "            else:\n",
    "                print(f'no url for query: {pq.query}')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: trie\n",
      "Results:\n",
      "http://www.triedntruetattoo.com\n",
      "no url for query: triest\n",
      "http://avalon.unomaha.edu\n",
      "no url for query: tried and failed\n",
      "no url for query: tried and truechildren's consignment sale\n",
      "['tried and true tattoo', 'triest', 'triethanalomine', 'tried and failed', \"tried and truechildren's consignment sale\"]\n"
     ]
    }
   ],
   "source": [
    "inp = \"trie\"\n",
    "print(\"Query:\", inp)\n",
    "print(\"Results:\")\n",
    "res = complete_user_query(inp, aol_trie, print_urls=True)\n",
    "print(res)\n",
    "\n",
    "#NB we assume you return suggested query string only\n",
    "assert res[0] == \"tried and true tattoo\"\n",
    "assert res[1] == \"triest\" or res[1] == \"triethanalomine\"\n",
    "\n",
    "assert \"boys and girls club of conyers georgia\" \\\n",
    "            in complete_user_query(\"boys girls club conyers\", aol_trie, 10), \"Should be here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measure suggest speed ##\n",
    "\n",
    "### 3.1. [10] Full Trie test\n",
    "\n",
    "Check how fast your search is working. Consider changing your code if it takes too long on average.\n",
    "\n",
    "Sucess criterion:\n",
    "- there is an average and a standard deviation for **multiple runs** of the given bucket.\n",
    "- there is an average and a standard deviation for **multiple runs** of naive search in the unindexed dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXECUTION TIME: INDEXED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per query with the index data structure : \n",
      "\n",
      "27.2 ms ± 843 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "39.9 ms ± 2.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "9.01 µs ± 161 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "90.3 µs ± 3.55 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "40 µs ± 1.72 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "357 µs ± 12.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "23.8 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "38 µs ± 1.48 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "35.4 ms ± 2.99 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "26.8 µs ± 2.22 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "2.3 ms ± 185 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "inp_queries = [\"inf\", \"the best \", \"information retrieval\", \"sherlock hol\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"inter\", \"USA sta\", \"Barbara \"]\n",
    "\n",
    "# measure avg execution time (in milliseconds) per query and print it out\n",
    "print(\"Time per query with the index data structure : \\n\")\n",
    "\n",
    "# let's try to save the results of the runs\n",
    "run_results = []\n",
    "# run_results = [%timeit -o complete_user_query(q, aol_trie, 1) for q in inp_queries]\n",
    "for query in inp_queries:\n",
    "    run = %timeit -o complete_user_query(query, aol_trie, 1)\n",
    "    run_results.append(run.all_runs[:10]) # saving the execution time (not the object itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inf</th>\n",
       "      <th>the best</th>\n",
       "      <th>information retrieval</th>\n",
       "      <th>sherlock hol</th>\n",
       "      <th>carnegie mell</th>\n",
       "      <th>babies r</th>\n",
       "      <th>new york</th>\n",
       "      <th>googol</th>\n",
       "      <th>inter</th>\n",
       "      <th>USA sta</th>\n",
       "      <th>Barbara</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.023913</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.031364</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.031335</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           inf  the best   information retrieval  sherlock hol  carnegie mell  \\\n",
       "std   0.000843   0.000002               0.000002      0.000004       0.000002   \n",
       "mean  0.023913   0.000035               0.000079      0.000079       0.000035   \n",
       "\n",
       "      babies r  new york    googol     inter   USA sta  Barbara   \n",
       "std   0.001258  0.001172  0.000001  0.002985  0.000002  0.000002  \n",
       "mean  0.031364  0.021000  0.000033  0.031335  0.000024  0.000020  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = [0.1, 10 ** -4, 10 ** -4, 10 ** -4, 10 ** -4, 0.1, 0.1, 10 ** -4, 0.1, 10 ** -4, 10 ** -4]\n",
    "runs_t = [list(map(lambda x: x * u, run)) for run, u in zip(run_results, units)]\n",
    "results = pd.DataFrame(data=dict(zip(inp_queries, runs_t)))\n",
    "# the table aboves saves the results of the first 10 runs of the indexed search for each query\n",
    "# let's calculate the variance and mean\n",
    "def add_stats(row):\n",
    "    row['std'] = np.std(row)\n",
    "    row['mean'] = np.mean(row)\n",
    "    return row \n",
    "\n",
    "r = results.T.apply(add_stats, axis=1).loc[:, ['std', 'mean']].T\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above displays both the mean and the standard deviation of the execution time accross 10 runs for the indexed search function:\n",
    "* for the query *inf*, the indexed search function takes 0.023 seconds (23 milliseconds) on average (across 10 runs) with a standard deviation of only 0.0008 we can expect the execution time to be within (21 milliseconds and 25 milliseconds)  \n",
    "\n",
    "* for the query *inter*, the indexed search function takes 0.023 seconds (23 milliseconds) on average (across 10 runs) with a standard deviation of only 0.0008 we can expect the execution time to be within (21 milliseconds and 25 milliseconds)  \n",
    "\n",
    "* The execution time for queries unseen in the training (e.g information retrieval) data is quite small as the trie index enable to quickly determine such queries without extra overhead.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXECUTION TIME: UNINDEXED SEARCH (NAIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_queries = [\"inf\", \"the best \", \"information retrieval\", \"sherlock hol\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"inter\", \"USA sta\", \"Barbara \"]\n",
    "\n",
    "\n",
    "# let's rewrite the code to use the dataset directly without the trie index\n",
    "def complete_user_query_unindexed(query, dataset, top_k=5):\n",
    "    freq = {}\n",
    "    for _, row in dataset.loc[dataset['query'].str.startswith(query, na=False)].iterrows():\n",
    "        if type(row['query']) == str:\n",
    "            if freq.get(row['query']) is None:\n",
    "                freq[row['query']] = 0\n",
    "            freq[row['query']] += 1\n",
    "    return sorted(freq.keys(), reverse=True, key=lambda x: freq[x])[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per query (Unindexed dataset): \n",
      "\n",
      "1.81 s ± 47.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.63 s ± 52.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.52 s ± 25.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.5 s ± 26.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.52 s ± 37.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.55 s ± 40.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.85 s ± 46.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.54 s ± 33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.18 s ± 48.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.46 s ± 19.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.5 s ± 42.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Time per query (Unindexed dataset): \\n\")\n",
    "\n",
    "# let's try to save the results of the runs\n",
    "run_results = []\n",
    "# run_results = [%timeit -o complete_user_query(q, aol_trie, 1) for q in inp_queries]\n",
    "for query in inp_queries:\n",
    "    run = %timeit -o complete_user_query_unindexed(query, aol_data, 1)\n",
    "    run_results.append(run.all_runs[:10]) # saving the execution time for the first 10 runs (not the object itself)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inf</th>\n",
       "      <th>the best</th>\n",
       "      <th>information retrieval</th>\n",
       "      <th>sherlock hol</th>\n",
       "      <th>carnegie mell</th>\n",
       "      <th>babies r</th>\n",
       "      <th>new york</th>\n",
       "      <th>googol</th>\n",
       "      <th>inter</th>\n",
       "      <th>USA sta</th>\n",
       "      <th>Barbara</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.047106</td>\n",
       "      <td>0.052809</td>\n",
       "      <td>0.025594</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.037463</td>\n",
       "      <td>0.040792</td>\n",
       "      <td>0.046166</td>\n",
       "      <td>0.033002</td>\n",
       "      <td>0.048356</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.042546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.588572</td>\n",
       "      <td>1.435721</td>\n",
       "      <td>1.336359</td>\n",
       "      <td>1.319440</td>\n",
       "      <td>1.336617</td>\n",
       "      <td>1.365361</td>\n",
       "      <td>1.624975</td>\n",
       "      <td>1.347300</td>\n",
       "      <td>1.917363</td>\n",
       "      <td>1.283905</td>\n",
       "      <td>1.317676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           inf  the best   information retrieval  sherlock hol  carnegie mell  \\\n",
       "std   0.047106   0.052809               0.025594      0.026308       0.037463   \n",
       "mean  1.588572   1.435721               1.336359      1.319440       1.336617   \n",
       "\n",
       "      babies r  new york    googol     inter   USA sta  Barbara   \n",
       "std   0.040792  0.046166  0.033002  0.048356  0.019132  0.042546  \n",
       "mean  1.365361  1.624975  1.347300  1.917363  1.283905  1.317676  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data=dict(zip(inp_queries, run_results)))\n",
    "# the table aboves saves the results of the first 10 runs of the indexed search for each query\n",
    "# let's calculate the variance and mean\n",
    "def add_stats(row):\n",
    "    row['std'] = np.std(row)\n",
    "    row['mean'] = np.mean(row)\n",
    "    return row \n",
    "\n",
    "r = results.T.apply(add_stats, axis=1).loc[:, ['std', 'mean']].T\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above displays both the mean and the standard deviation of the execution time accross 10 runs for the naif unindexed search function:\n",
    "* for the query *inf*, the indexed search function takes 1.58 seconds on average (across 10 runs) with a 0.047 standard deviation. We can expect the execution time to be within (1.73 seconds and 1.43 seconds).  \n",
    "Notice that the performance is more than 7 times slower than the indexed search function\n",
    "\n",
    "* for the query *inter*, the indexed search function takes 1.91 seconds on average (across 10 runs) with a 0.048 standard deviation. We can expect the execution time to be within (2.1 seconds and 1.7 seconds).  \n",
    "Notice that the performance is more than 7 times slower than the indexed search function\n",
    "\n",
    "* The execution time between the different queries is not so significant as the naif method ends up scanning most of the dataset regardless of whether the query was seen before or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [10] Add spellchecking to your suggest\n",
    "\n",
    "Try to make your search results as close as possible. Compare top-5 results of each query with top-5 results for corrected.\n",
    "\n",
    "You can use use [pyspellchecker](https://pypi.org/project/pyspellchecker/) `candidates()` call, or use any other spellchecker implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\bouab\\dev\\se_env\\lib\\site-packages (0.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\bouab\\dev\\se_env\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the spell checker\n",
    "!pip install -U pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this text is full of extra characters it needs to be cleaned\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "# spell.word_frequency.load_words(['mell'])\n",
    "# first of all let's create a dictionary of the words and their frequencies in our dataset\n",
    "from collections import Counter\n",
    "word_freq = Counter()\n",
    "\n",
    "punc = r'[#%&\\(\\)\\*\\+,\\/:;<=>@\\[\\\\\\]\\^_`{\\|}~\\$-]+'\n",
    "\n",
    "# this function is needed for cleaning the text\n",
    "def process_text(text):\n",
    "    if text is None: \n",
    "        return\n",
    "    \n",
    "    # a minimal data processing\n",
    "    text = text.lower().strip()\n",
    "    # remove any non desirable characters: \n",
    "    text = re.sub(punc, '', text)\n",
    "\n",
    "    # remove any segment of text where there is not alphabetic characters within alphabetic characters\n",
    "    regex = r'(\\w+[^a-zA-Z1-9\\s]+)*(\\w+[^a-zA-Z1-9\\s]+\\w+)'    \n",
    "    text = re.sub(regex, ' ', text)\n",
    "\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    if len(text) > 0:     \n",
    "        return text\n",
    "    \n",
    "    return \n",
    "\n",
    "t = 'thi**s t@@ex~t is full of extra[] characters, it need##s to b%e cleaned__'\n",
    "print(process_text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'dfdf': 2,\n",
       "         'ad2d': 2,\n",
       "         '530': 32,\n",
       "         'merit': 93,\n",
       "         'release': 678,\n",
       "         'appearance': 41,\n",
       "         'lottery': 6174,\n",
       "         'susheme': 1,\n",
       "         'p': 1128,\n",
       "         '.': 18900,\n",
       "         \"p'\": 5,\n",
       "         \"'\": 1646,\n",
       "         'buddylis': 1,\n",
       "         'vietnam': 705,\n",
       "         'googl': 132,\n",
       "         'ozark': 111,\n",
       "         'horse': 3486,\n",
       "         'blankets': 164,\n",
       "         'gall': 115,\n",
       "         'stones': 553,\n",
       "         'gallstones': 15,\n",
       "         'http': 25004,\n",
       "         'photos': 6972,\n",
       "         '88145967': 4,\n",
       "         '24368586': 4,\n",
       "         'in': 90091,\n",
       "         'pool32148876': 4,\n",
       "         'href': 380,\n",
       "         'a': 33791,\n",
       "         'alt': 238,\n",
       "         'files': 786,\n",
       "         'dellcomputers': 5,\n",
       "         'cascadefamilymedical': 1,\n",
       "         'pop': 652,\n",
       "         'up': 4996,\n",
       "         'adds': 99,\n",
       "         'the': 77080,\n",
       "         'childs': 85,\n",
       "         'wonderland': 121,\n",
       "         'company': 3824,\n",
       "         'grand': 3123,\n",
       "         'rapids': 380,\n",
       "         'michigan': 4238,\n",
       "         'co.': 1150,\n",
       "         'budget': 611,\n",
       "         'truck': 3374,\n",
       "         'rental': 3739,\n",
       "         'adr': 19,\n",
       "         'wheels': 1612,\n",
       "         'holiday': 1341,\n",
       "         'mansion': 196,\n",
       "         'houseboat': 60,\n",
       "         'back': 2494,\n",
       "         'to': 43252,\n",
       "         'future': 460,\n",
       "         'konig': 15,\n",
       "         'jet': 1296,\n",
       "         'blue': 6210,\n",
       "         'airlines': 6551,\n",
       "         'coats': 77,\n",
       "         'tire': 637,\n",
       "         'equipment': 2082,\n",
       "         'verizon': 2336,\n",
       "         'wireless': 1690,\n",
       "         'titlesourceinc': 1,\n",
       "         'select': 169,\n",
       "         'business': 4228,\n",
       "         'services': 3508,\n",
       "         'title': 554,\n",
       "         'cbc': 48,\n",
       "         'companies': 1685,\n",
       "         'national': 5153,\n",
       "         'real': 8484,\n",
       "         'estate': 6800,\n",
       "         'settlement': 203,\n",
       "         'pennsylvania': 1990,\n",
       "         'sunbury': 14,\n",
       "         'atm': 35,\n",
       "         'corporation': 843,\n",
       "         'cheasapeake': 1,\n",
       "         'appraisal': 312,\n",
       "         'and': 63891,\n",
       "         'chesapeake': 243,\n",
       "         'first': 4153,\n",
       "         'american': 14472,\n",
       "         'lenders': 94,\n",
       "         'advantage': 282,\n",
       "         'united': 4135,\n",
       "         'one': 4550,\n",
       "         'resources': 609,\n",
       "         'credit': 6304,\n",
       "         'plus': 2166,\n",
       "         'solutions': 495,\n",
       "         'group': 2220,\n",
       "         'security': 2877,\n",
       "         'search': 5117,\n",
       "         'abstract': 185,\n",
       "         'searchtec': 2,\n",
       "         'fiserv': 9,\n",
       "         'integrated': 30,\n",
       "         'loan': 1153,\n",
       "         'michael': 2779,\n",
       "         'keaton': 17,\n",
       "         'date': 977,\n",
       "         'of': 107690,\n",
       "         'birth': 1683,\n",
       "         'auto': 5311,\n",
       "         'locator': 284,\n",
       "         'kentucky': 2017,\n",
       "         'fried': 273,\n",
       "         'chicken': 1955,\n",
       "         'shamokin': 12,\n",
       "         'dam': 172,\n",
       "         'menu': 673,\n",
       "         'ford': 5848,\n",
       "         '4196449191': 1,\n",
       "         'target': 1532,\n",
       "         'bowling': 888,\n",
       "         'green': 2806,\n",
       "         'state': 13569,\n",
       "         'university': 8454,\n",
       "         'rug': 238,\n",
       "         'black': 10514,\n",
       "         'orange': 1896,\n",
       "         'rectangle': 21,\n",
       "         'google': 34971,\n",
       "         'wnmu': 13,\n",
       "         'homepage': 331,\n",
       "         'home': 13777,\n",
       "         'page': 2264,\n",
       "         'webct': 24,\n",
       "         'glitter': 489,\n",
       "         'mx.': 1,\n",
       "         'www': 12203,\n",
       "         'com': 15063,\n",
       "         'weather': 6874,\n",
       "         'wetherchannel': 2,\n",
       "         'weatherchannel': 65,\n",
       "         'zip': 1690,\n",
       "         'codes': 5457,\n",
       "         'dana': 470,\n",
       "         'reeves': 220,\n",
       "         'dies': 146,\n",
       "         'harry': 1531,\n",
       "         'david': 3130,\n",
       "         'college': 9512,\n",
       "         'savings': 1008,\n",
       "         'plan': 1579,\n",
       "         'amc': 385,\n",
       "         'crossing': 347,\n",
       "         'kbb': 121,\n",
       "         'remax': 1073,\n",
       "         'torn': 162,\n",
       "         'cornea': 28,\n",
       "         'treatment': 1244,\n",
       "         'dog': 5930,\n",
       "         '1999': 372,\n",
       "         'honda': 3070,\n",
       "         'accord': 275,\n",
       "         'check': 1333,\n",
       "         'engine': 1865,\n",
       "         'light': 2016,\n",
       "         'reset': 101,\n",
       "         'pa': 5793,\n",
       "         'emissions': 35,\n",
       "         'fuel': 887,\n",
       "         'additives': 40,\n",
       "         'turn': 584,\n",
       "         'off': 1674,\n",
       "         'walmart': 2496,\n",
       "         'people': 5232,\n",
       "         'bare': 649,\n",
       "         'minerals': 256,\n",
       "         'make': 3746,\n",
       "         'painters': 238,\n",
       "         'pergola': 58,\n",
       "         'house': 7287,\n",
       "         'entrance': 105,\n",
       "         'accountlinkk': 1,\n",
       "         'accountlink': 11,\n",
       "         'irs': 1697,\n",
       "         'publication': 43,\n",
       "         'prestonandsteve': 1,\n",
       "         'us': 5808,\n",
       "         'constitution': 209,\n",
       "         'center': 8154,\n",
       "         'philadelphia': 2269,\n",
       "         'rocky': 576,\n",
       "         'statue': 305,\n",
       "         'art': 6660,\n",
       "         'museum': 1550,\n",
       "         'independence': 370,\n",
       "         'mall': 1735,\n",
       "         'babiesrus': 179,\n",
       "         'lily': 325,\n",
       "         'pads': 248,\n",
       "         'breast': 2405,\n",
       "         'boppy': 7,\n",
       "         'covers': 1130,\n",
       "         'once': 163,\n",
       "         'upon': 97,\n",
       "         'child': 3837,\n",
       "         'scott': 1062,\n",
       "         'braxton': 110,\n",
       "         'hicks': 361,\n",
       "         'contractions': 87,\n",
       "         'foods': 1267,\n",
       "         'avoid': 68,\n",
       "         'when': 2784,\n",
       "         'pregnant': 1299,\n",
       "         'feeding': 251,\n",
       "         'infant': 425,\n",
       "         'innoculation': 6,\n",
       "         'safety': 1160,\n",
       "         'hepatitis': 304,\n",
       "         'b': 1951,\n",
       "         'vaccine': 88,\n",
       "         'infants': 157,\n",
       "         'roth': 170,\n",
       "         'ira': 233,\n",
       "         'calculator': 1443,\n",
       "         'estimated': 30,\n",
       "         'value': 1148,\n",
       "         'at': 9119,\n",
       "         'retirement': 673,\n",
       "         'sears': 1439,\n",
       "         'script': 293,\n",
       "         'language': 1178,\n",
       "         'fit': 253,\n",
       "         'pregnancy': 2437,\n",
       "         'baby': 6386,\n",
       "         'carside': 1,\n",
       "         'names': 3384,\n",
       "         'mortgage': 1441,\n",
       "         'inducing': 32,\n",
       "         'vomiting': 97,\n",
       "         'defication': 1,\n",
       "         'eats': 54,\n",
       "         'uncooked': 4,\n",
       "         'pasta': 440,\n",
       "         'aaroncarter': 6,\n",
       "         'jesse': 671,\n",
       "         'mccartney': 521,\n",
       "         'popstarmagizine': 1,\n",
       "         'popstarmagazine': 1,\n",
       "         'popstar': 31,\n",
       "         'mag': 165,\n",
       "         'jessemccartney': 23,\n",
       "         'hollywoodrecords': 1,\n",
       "         'c': 2519,\n",
       "         '.com': 11692,\n",
       "         'movie': 6576,\n",
       "         'theaters': 540,\n",
       "         'peru': 188,\n",
       "         'il': 1532,\n",
       "         'illinois': 3499,\n",
       "         'cenima': 5,\n",
       "         'cinema': 407,\n",
       "         'theater': 1863,\n",
       "         'showings': 12,\n",
       "         'jojo': 105,\n",
       "         'lyrics': 18509,\n",
       "         'recycleable': 3,\n",
       "         'items': 521,\n",
       "         'shrecycleable': 1,\n",
       "         'spring': 1718,\n",
       "         'valley': 3003,\n",
       "         'girls': 10792,\n",
       "         'softball': 1363,\n",
       "         'new': 26552,\n",
       "         'mexico': 2904,\n",
       "         'll': 329,\n",
       "         'be': 2883,\n",
       "         'funny': 2772,\n",
       "         'our': 1210,\n",
       "         'groupjesse': 1,\n",
       "         'tarantula': 28,\n",
       "         'hawk': 189,\n",
       "         'wasp': 84,\n",
       "         'jmacconnectino': 1,\n",
       "         'jmacconnection': 1,\n",
       "         'kidsonlilne': 1,\n",
       "         'schedule': 1573,\n",
       "         'philshockeyteam': 1,\n",
       "         'cliffnotes': 19,\n",
       "         'cliff': 285,\n",
       "         'notes': 658,\n",
       "         'war': 3510,\n",
       "         'worlds': 380,\n",
       "         'learntospeakblack': 1,\n",
       "         'wowr': 1,\n",
       "         'dmv': 992,\n",
       "         'poker': 1812,\n",
       "         'smosh': 1,\n",
       "         'wow': 411,\n",
       "         'lvl': 3,\n",
       "         '30': 561,\n",
       "         'guide': 2093,\n",
       "         'chuck': 593,\n",
       "         'norris': 207,\n",
       "         'w': 974,\n",
       "         'counterstrike': 12,\n",
       "         'counter': 439,\n",
       "         'strike': 151,\n",
       "         'hernias': 37,\n",
       "         'silive': 40,\n",
       "         'hernia': 321,\n",
       "         'doctors': 628,\n",
       "         'newgrounds': 108,\n",
       "         'thedarkside': 1,\n",
       "         'switch': 466,\n",
       "         'chaiyya': 1,\n",
       "         'cstoons': 2,\n",
       "         'spit': 35,\n",
       "         'ball': 1695,\n",
       "         'with': 14064,\n",
       "         'straw': 81,\n",
       "         'spitball': 1,\n",
       "         'babble': 10,\n",
       "         'bubble': 454,\n",
       "         'so': 1240,\n",
       "         'popular': 388,\n",
       "         'accessories': 1633,\n",
       "         'charles': 1472,\n",
       "         'drew': 467,\n",
       "         'car': 9094,\n",
       "         'military': 1712,\n",
       "         'benfits': 10,\n",
       "         'benefits': 849,\n",
       "         'deers': 5,\n",
       "         'id': 1051,\n",
       "         'cards': 5772,\n",
       "         'army': 1813,\n",
       "         'tricare': 70,\n",
       "         'publix': 65,\n",
       "         'waldrop': 11,\n",
       "         'hills': 1328,\n",
       "         'sprint': 1080,\n",
       "         'phones': 1459,\n",
       "         'fafsa': 440,\n",
       "         'georgia': 4596,\n",
       "         'clayton': 223,\n",
       "         'perimeter': 80,\n",
       "         'saint': 1304,\n",
       "         'philiphs': 1,\n",
       "         'routing': 35,\n",
       "         'number': 2440,\n",
       "         'for': 69111,\n",
       "         'bank': 10697,\n",
       "         'america': 5804,\n",
       "         'texas': 10639,\n",
       "         'marriage': 947,\n",
       "         'lisence': 45,\n",
       "         'licence': 253,\n",
       "         'guardianship': 60,\n",
       "         'laws': 1761,\n",
       "         'conservator': 5,\n",
       "         'dekalb': 210,\n",
       "         'county': 22352,\n",
       "         'probate': 264,\n",
       "         'veterans': 361,\n",
       "         'understanding': 146,\n",
       "         'fractions': 157,\n",
       "         '4id': 1,\n",
       "         'linen': 205,\n",
       "         'n': 3242,\n",
       "         'things': 1401,\n",
       "         'bed': 2970,\n",
       "         'bath': 1697,\n",
       "         'beyond': 848,\n",
       "         'depot': 1874,\n",
       "         'wardrobe': 99,\n",
       "         'storage': 1088,\n",
       "         'va': 3672,\n",
       "         'lost': 1139,\n",
       "         'nintendo': 374,\n",
       "         'ds': 266,\n",
       "         'trace': 173,\n",
       "         'memory': 445,\n",
       "         'sixflags': 27,\n",
       "         'mwr': 22,\n",
       "         'fort': 2388,\n",
       "         'mcpherson': 61,\n",
       "         'preteen': 1037,\n",
       "         'birthday': 3125,\n",
       "         'party': 4828,\n",
       "         'sciencetrek': 3,\n",
       "         'science': 2653,\n",
       "         'trek': 307,\n",
       "         'visit': 248,\n",
       "         'scitrek': 2,\n",
       "         'fandngo': 1,\n",
       "         'fandango': 219,\n",
       "         'shower': 2079,\n",
       "         'ideas': 2441,\n",
       "         'enterprise': 620,\n",
       "         'rent': 3595,\n",
       "         'avis': 203,\n",
       "         'priceline': 230,\n",
       "         'city': 14261,\n",
       "         'mapquest': 8898,\n",
       "         'brooke': 281,\n",
       "         'medical': 4131,\n",
       "         'burn': 412,\n",
       "         'unit': 500,\n",
       "         'suze': 22,\n",
       "         'orman': 20,\n",
       "         'force': 1100,\n",
       "         'progressive': 256,\n",
       "         'patina': 23,\n",
       "         'patinia': 1,\n",
       "         'hyundai': 325,\n",
       "         'gear': 674,\n",
       "         'shift': 89,\n",
       "         'knob': 45,\n",
       "         'pantina': 1,\n",
       "         'ingles': 48,\n",
       "         'grocery': 383,\n",
       "         'cakes': 1060,\n",
       "         'kroger': 71,\n",
       "         'butterfly': 752,\n",
       "         'kids': 4941,\n",
       "         'cake': 2158,\n",
       "         'designs': 1977,\n",
       "         'tulle': 13,\n",
       "         'butterflies': 200,\n",
       "         'how': 19326,\n",
       "         'amscan': 4,\n",
       "         'shimmering': 4,\n",
       "         'inglesmarket': 1,\n",
       "         'order': 1302,\n",
       "         'irthday': 1,\n",
       "         'online': 10838,\n",
       "         'kudzu': 7,\n",
       "         'dairy': 344,\n",
       "         'queen': 1195,\n",
       "         'virginia': 5217,\n",
       "         'minor': 415,\n",
       "         'is': 11992,\n",
       "         'it': 3954,\n",
       "         'necessary': 64,\n",
       "         'guardian': 161,\n",
       "         'minors': 45,\n",
       "         'babies': 975,\n",
       "         'r': 2308,\n",
       "         'lowes': 1173,\n",
       "         'door': 1827,\n",
       "         'viewer': 65,\n",
       "         'peep': 40,\n",
       "         'hole': 397,\n",
       "         'peephole': 2,\n",
       "         'custom': 1939,\n",
       "         'atlanta': 2482,\n",
       "         'ga': 3238,\n",
       "         'dolly': 188,\n",
       "         'madison': 820,\n",
       "         'midas': 96,\n",
       "         'meineke': 5,\n",
       "         'firestone': 55,\n",
       "         'purple': 822,\n",
       "         'foot': 1155,\n",
       "         'express': 1988,\n",
       "         'kumon': 5,\n",
       "         'jeeves': 2057,\n",
       "         'wamu': 191,\n",
       "         'ft': 788,\n",
       "         'build': 993,\n",
       "         'bear': 1287,\n",
       "         'yahoo': 23489,\n",
       "         'microsoft': 1487,\n",
       "         'aim': 657,\n",
       "         'christian': 3149,\n",
       "         'academy': 1489,\n",
       "         'crossroads': 145,\n",
       "         'ellenwood': 5,\n",
       "         'allstars': 53,\n",
       "         'summer': 2343,\n",
       "         'camp': 1975,\n",
       "         'trust': 633,\n",
       "         'fun': 1408,\n",
       "         'cingular': 1431,\n",
       "         'pizzahut': 35,\n",
       "         'columbus': 1184,\n",
       "         'forcolumbus': 1,\n",
       "         'taxes': 789,\n",
       "         'gsu': 1,\n",
       "         'georgw': 1,\n",
       "         'washington': 4622,\n",
       "         'george': 2548,\n",
       "         'shurgard': 2,\n",
       "         'centers': 848,\n",
       "         'uhaul': 190,\n",
       "         'oil': 2327,\n",
       "         'change': 1497,\n",
       "         'tuneup': 20,\n",
       "         'clinic': 718,\n",
       "         'tune': 81,\n",
       "         'care': 3617,\n",
       "         'martha': 608,\n",
       "         'liing': 1,\n",
       "         'living': 1831,\n",
       "         'cato': 22,\n",
       "         'gpc': 1,\n",
       "         'tmobile': 784,\n",
       "         'jewelery': 138,\n",
       "         'jewerly': 149,\n",
       "         'stores': 3035,\n",
       "         'jewelry': 2415,\n",
       "         'mom': 885,\n",
       "         'rings': 1076,\n",
       "         'raven': 741,\n",
       "         'simone': 118,\n",
       "         'thats': 143,\n",
       "         'north': 6096,\n",
       "         'springs': 2128,\n",
       "         'high': 10486,\n",
       "         'school': 18041,\n",
       "         'poison': 373,\n",
       "         'control': 1731,\n",
       "         'hydocortisone': 4,\n",
       "         'impetigo': 36,\n",
       "         'jvc': 78,\n",
       "         'hallmark': 436,\n",
       "         'best': 5717,\n",
       "         'buy': 3609,\n",
       "         'cheese': 880,\n",
       "         'factory': 836,\n",
       "         'cheesecake': 204,\n",
       "         'apartments': 2567,\n",
       "         'cheerleading': 601,\n",
       "         'lithonia': 36,\n",
       "         'elllenwood': 1,\n",
       "         'belly': 467,\n",
       "         'dancing': 771,\n",
       "         'better': 1074,\n",
       "         'death': 2195,\n",
       "         'grays': 36,\n",
       "         'anatomy': 1011,\n",
       "         'usps': 643,\n",
       "         'ups': 985,\n",
       "         'investigation': 138,\n",
       "         'st': 3804,\n",
       "         'philips': 134,\n",
       "         'goodyear': 69,\n",
       "         'hyundaiusa': 1,\n",
       "         'parts': 7022,\n",
       "         'napa': 404,\n",
       "         'aotu': 3,\n",
       "         'j': 1726,\n",
       "         'whitney': 639,\n",
       "         'pattern': 926,\n",
       "         'plate': 488,\n",
       "         'atozone': 1,\n",
       "         'autozone': 102,\n",
       "         'advance': 458,\n",
       "         'remove': 408,\n",
       "         'adware': 69,\n",
       "         'from': 9139,\n",
       "         'computer': 2396,\n",
       "         'mailbox': 1084,\n",
       "         'jc': 882,\n",
       "         'hyndai': 3,\n",
       "         'elantra': 44,\n",
       "         'recalls': 123,\n",
       "         'meadow': 138,\n",
       "         'creek': 1889,\n",
       "         'football': 1878,\n",
       "         'youth': 1604,\n",
       "         'meadowcreek': 3,\n",
       "         'park': 7436,\n",
       "         'greater': 207,\n",
       "         'lilburn': 20,\n",
       "         'athletic': 338,\n",
       "         'association': 2573,\n",
       "         'tucker': 141,\n",
       "         'cheerlading': 1,\n",
       "         'cheer': 281,\n",
       "         'adaware': 71,\n",
       "         'gwinnett': 184,\n",
       "         'parks': 1885,\n",
       "         'mercies': 2,\n",
       "         'associations': 143,\n",
       "         'norcross': 24,\n",
       "         'lucky': 321,\n",
       "         'shoals': 47,\n",
       "         'friend': 887,\n",
       "         'track': 1393,\n",
       "         'field': 1079,\n",
       "         'gymnastics': 357,\n",
       "         'ymca': 516,\n",
       "         'autosave': 1,\n",
       "         'alamo': 242,\n",
       "         'omnicancun': 3,\n",
       "         'wyoming': 433,\n",
       "         'junonia': 5,\n",
       "         'coupons': 1522,\n",
       "         'tip': 123,\n",
       "         'tennis': 825,\n",
       "         'instructor': 92,\n",
       "         'okay': 35,\n",
       "         'give': 682,\n",
       "         'money': 2287,\n",
       "         'tipping': 46,\n",
       "         'toys': 1760,\n",
       "         'year': 1844,\n",
       "         'discovery': 434,\n",
       "         'scale': 437,\n",
       "         'measures': 66,\n",
       "         'body': 3797,\n",
       "         'fat': 2183,\n",
       "         'water': 4569,\n",
       "         'img': 151,\n",
       "         'dominos': 168,\n",
       "         'pizza': 1295,\n",
       "         \"lil'\": 34,\n",
       "         'movers': 100,\n",
       "         'bus': 1082,\n",
       "         'fisherprice': 25,\n",
       "         'cheerleader': 246,\n",
       "         'nation': 314,\n",
       "         'tv': 4975,\n",
       "         'show': 4617,\n",
       "         'lifetime': 126,\n",
       "         'lil': 883,\n",
       "         'clothing': 2972,\n",
       "         'store': 4086,\n",
       "         'silhouettes': 35,\n",
       "         'pogo': 3051,\n",
       "         'apple': 1185,\n",
       "         'ipodnano': 4,\n",
       "         'pc': 1516,\n",
       "         'dominoes': 151,\n",
       "         'game': 5853,\n",
       "         'uterine': 98,\n",
       "         'bleeding': 560,\n",
       "         'coumadin': 58,\n",
       "         'free': 44489,\n",
       "         'ecards': 1603,\n",
       "         'barnes': 849,\n",
       "         'noble': 643,\n",
       "         'children': 3985,\n",
       "         'who': 3503,\n",
       "         'have': 2248,\n",
       "         'died': 338,\n",
       "         'moms': 878,\n",
       "         'postpartum': 55,\n",
       "         'depression': 956,\n",
       "         'rotovirus': 12,\n",
       "         'aol': 10058,\n",
       "         'fix': 440,\n",
       "         'me': 4586,\n",
       "         'delete': 407,\n",
       "         'temporary': 238,\n",
       "         'outback': 189,\n",
       "         'steakhouse': 256,\n",
       "         'cause': 743,\n",
       "         'sensitivity': 51,\n",
       "         'deaths': 350,\n",
       "         'women': 7646,\n",
       "         'suffering': 43,\n",
       "         'deprssion': 2,\n",
       "         'each': 201,\n",
       "         'statistics': 862,\n",
       "         'on': 23871,\n",
       "         'had': 476,\n",
       "         'psychosis': 31,\n",
       "         'due': 271,\n",
       "         'depressionpr': 1,\n",
       "         'edinburgh': 33,\n",
       "         'postnatal': 2,\n",
       "         'epds': 2,\n",
       "         'cdc': 54,\n",
       "         'infancide': 1,\n",
       "         'infanticide': 8,\n",
       "         'pictires': 7,\n",
       "         'tom': 1372,\n",
       "         'cruise': 2029,\n",
       "         'his': 905,\n",
       "         'wife': 1527,\n",
       "         'magazines': 427,\n",
       "         'pictures': 21419,\n",
       "         'katie': 402,\n",
       "         'holmes': 375,\n",
       "         'meaning': 787,\n",
       "         'cohort': 5,\n",
       "         'study': 870,\n",
       "         'prospective': 6,\n",
       "         'case': 1296,\n",
       "         'longitudinal': 9,\n",
       "         'anticholinergic': 4,\n",
       "         'parasympathetic': 2,\n",
       "         'nerve': 381,\n",
       "         'impulses': 1,\n",
       "         'hypertonicity': 1,\n",
       "         'dopamine': 8,\n",
       "         'cortisol': 32,\n",
       "         'norepinephrin': 4,\n",
       "         'rxonline': 2,\n",
       "         'dictionary': 3849,\n",
       "         'webmd': 686,\n",
       "         'pharmaceutical': 185,\n",
       "         'dictionaries': 25,\n",
       "         'blues': 627,\n",
       "         'amazon': 959,\n",
       "         'showcase': 126,\n",
       "         'cinamas': 8,\n",
       "         'cinemas': 312,\n",
       "         'travelocity': 927,\n",
       "         'social': 2478,\n",
       "         'disability': 634,\n",
       "         'challenge': 222,\n",
       "         'mrsa': 62,\n",
       "         'mrsawebmd': 1,\n",
       "         'gifts': 1583,\n",
       "         'workers': 486,\n",
       "         'nurses': 337,\n",
       "         'teach': 156,\n",
       "         'breastfeeding': 136,\n",
       "         'board': 2937,\n",
       "         'public': 3903,\n",
       "         'utilities': 130,\n",
       "         'cheyenne': 101,\n",
       "         'bopu': 2,\n",
       "         'phonenetic': 1,\n",
       "         'spelling': 214,\n",
       "         'phonetic': 9,\n",
       "         'cantine': 7,\n",
       "         'applebees': 98,\n",
       "         'red': 4742,\n",
       "         'envelope': 63,\n",
       "         'etoy': 2,\n",
       "         'bruising': 24,\n",
       "         'my': 18587,\n",
       "         'level': 609,\n",
       "         'normal': 418,\n",
       "         'cordless': 134,\n",
       "         'curling': 65,\n",
       "         'iron': 1379,\n",
       "         'ceramic': 557,\n",
       "         'straightener': 20,\n",
       "         'small': 1981,\n",
       "         'beaded': 215,\n",
       "         'jewlery': 327,\n",
       "         'tyco': 31,\n",
       "         'disney': 5636,\n",
       "         'line': 3115,\n",
       "         'castaway': 27,\n",
       "         'club': 6853,\n",
       "         'blood': 2419,\n",
       "         'clots': 56,\n",
       "         'while': 525,\n",
       "         'phlebitis': 25,\n",
       "         'activity': 177,\n",
       "         'phelbitis': 2,\n",
       "         'taco': 193,\n",
       "         'johns': 473,\n",
       "         'calories': 397,\n",
       "         'crock': 172,\n",
       "         'pot': 646,\n",
       "         'graduation': 1022,\n",
       "         'keepsake': 44,\n",
       "         'box': 1898,\n",
       "         'petiqie': 1,\n",
       "         'petique': 1,\n",
       "         'early': 937,\n",
       "         'signs': 1793,\n",
       "         'kidney': 460,\n",
       "         'failure': 295,\n",
       "         'betoveen': 1,\n",
       "         'beethoven': 47,\n",
       "         'song': 4633,\n",
       "         'foever': 3,\n",
       "         'you': 8718,\n",
       "         'forever': 503,\n",
       "         'reciepes': 35,\n",
       "         'recipes': 4960,\n",
       "         'gre': 125,\n",
       "         'exam': 1550,\n",
       "         'disneyworld': 202,\n",
       "         'vacation': 2121,\n",
       "         'packs': 134,\n",
       "         'packagess': 2,\n",
       "         'world': 7214,\n",
       "         'packages': 513,\n",
       "         'lladro': 46,\n",
       "         'bartholmuse': 1,\n",
       "         'absess': 3,\n",
       "         'bartholomeus': 8,\n",
       "         'abscess': 36,\n",
       "         'cheap': 4961,\n",
       "         'vacations': 1302,\n",
       "         'images': 2375,\n",
       "         'examples': 567,\n",
       "         'acronyms': 17,\n",
       "         'acronym': 19,\n",
       "         'poems': 3400,\n",
       "         'writing': 1038,\n",
       "         'dixie': 440,\n",
       "         'chicks': 531,\n",
       "         'songs': 2943,\n",
       "         'about': 4752,\n",
       "         'president': 836,\n",
       "         'bush': 1249,\n",
       "         'very': 629,\n",
       "         'merry': 27,\n",
       "         'christmas': 585,\n",
       "         'elton': 98,\n",
       "         'john': 6234,\n",
       "         'vegas': 4335,\n",
       "         'billy': 939,\n",
       "         'gene': 389,\n",
       "         'king': 3077,\n",
       "         'billygene': 1,\n",
       "         'time': 4214,\n",
       "         'traveocity': 4,\n",
       "         's': 3705,\n",
       "         'australia': 431,\n",
       "         'match.': 25,\n",
       "         'matchcom': 23,\n",
       "         'match': 505,\n",
       "         'ma': 2929,\n",
       "         'help': 3567,\n",
       "         'mimi': 66,\n",
       "         'pepper': 379,\n",
       "         'yahooh': 2,\n",
       "         'g': 1582,\n",
       "         'google.': 195,\n",
       "         'cheaptickets': 144,\n",
       "         'jpereyra': 5,\n",
       "         'jean': 596,\n",
       "         'pierre': 268,\n",
       "         'diamond': 1025,\n",
       "         'diamonds': 317,\n",
       "         'by': 10070,\n",
       "         'acrobat': 173,\n",
       "         'reader': 317,\n",
       "         'weider': 27,\n",
       "         'gym': 389,\n",
       "         'true': 726,\n",
       "         'tone': 211,\n",
       "         'joe': 1313,\n",
       "         'work': 2852,\n",
       "         'out': 3331,\n",
       "         'station': 1205,\n",
       "         'mens': 1216,\n",
       "         'shoes': 3957,\n",
       "         'little': 3982,\n",
       "         'rock': 3191,\n",
       "         'americanexpress': 109,\n",
       "         'doublepoints19': 2,\n",
       "         'rand': 213,\n",
       "         '71': 93,\n",
       "         '66': 172,\n",
       "         'ascemtive': 1,\n",
       "         'ringtones': 1508,\n",
       "         'arkansas': 1207,\n",
       "         'secretary': 384,\n",
       "         'info': 1232,\n",
       "         'funeral': 1197,\n",
       "         'homes': 8777,\n",
       "         'roller': 505,\n",
       "         'drummond': 31,\n",
       "         'chenal': 10,\n",
       "         'americanflag': 1,\n",
       "         'cleveland': 1458,\n",
       "         'thugz': 2,\n",
       "         'thugs4sex': 1,\n",
       "         'hertz': 285,\n",
       "         'kanye': 145,\n",
       "         'west': 5318,\n",
       "         'municipal': 246,\n",
       "         'dstrict': 2,\n",
       "         'district': 2860,\n",
       "         'mohawks': 3,\n",
       "         'hairstyles': 1340,\n",
       "         'mohawk': 105,\n",
       "         'gay': 4767,\n",
       "         'chatlines': 13,\n",
       "         'hairstyle': 166,\n",
       "         'african': 2587,\n",
       "         'alltel': 184,\n",
       "         'tuxedo': 100,\n",
       "         'junction': 313,\n",
       "         'bljk': 1,\n",
       "         'kinky': 216,\n",
       "         'twist': 273,\n",
       "         'aldo': 45,\n",
       "         'steve': 970,\n",
       "         'madden': 365,\n",
       "         'tuxeuo': 1,\n",
       "         'braids': 74,\n",
       "         'adam4adam': 499,\n",
       "         'syria': 21,\n",
       "         'history': 5712,\n",
       "         'historical': 601,\n",
       "         'events': 1209,\n",
       "         'golan': 10,\n",
       "         'heights': 617,\n",
       "         'om': 800,\n",
       "         'boxed': 26,\n",
       "         'set': 1313,\n",
       "         'fruits': 143,\n",
       "         'basket': 330,\n",
       "         'lovehina': 1,\n",
       "         'california': 7317,\n",
       "         'idaho': 1126,\n",
       "         'nevada': 1247,\n",
       "         'imvu': 6,\n",
       "         \"com'\": 6,\n",
       "         'anime': 1150,\n",
       "         'sushi': 118,\n",
       "         'zushi': 1,\n",
       "         'haus': 57,\n",
       "         'play': 2569,\n",
       "         'cpioinhndgberfrefgrbdnehfdnebc': 1,\n",
       "         'journals': 188,\n",
       "         'www.': 4437,\n",
       "         'wwwmyfloridahealthstat': 1,\n",
       "         'clearwater': 289,\n",
       "         'policestation': 1,\n",
       "         '.policestationdepatment': 1,\n",
       "         '.policestationdepartment': 2,\n",
       "         'senior': 755,\n",
       "         'jacksonville': 966,\n",
       "         'llc': 440,\n",
       "         'florida': 15768,\n",
       "         'department': 5406,\n",
       "         'corrections': 1080,\n",
       "         'wayne': 1144,\n",
       "         'process': 493,\n",
       "         'server': 212,\n",
       "         'professional': 749,\n",
       "         'regulations': 408,\n",
       "         'licensed': 90,\n",
       "         'atlantic': 1328,\n",
       "         'filters': 467,\n",
       "         'well': 542,\n",
       "         'driller': 10,\n",
       "         'citrus': 165,\n",
       "         'couts': 1,\n",
       "         'courts': 684,\n",
       "         'corporations': 119,\n",
       "         'cowboy': 583,\n",
       "         'boots': 750,\n",
       "         'lucchese': 19,\n",
       "         'stingray': 62,\n",
       "         'lee': 2134,\n",
       "         'atlanitc': 1,\n",
       "         'glove': 181,\n",
       "         'palm': 2956,\n",
       "         'beach': 10739,\n",
       "         'building': 1726,\n",
       "         'permits': 113,\n",
       "         'judge': 362,\n",
       "         'wroble': 19,\n",
       "         'arthur': 465,\n",
       "         'justice': 571,\n",
       "         'miami': 3315,\n",
       "         'dade': 355,\n",
       "         'clerk': 940,\n",
       "         'court': 3514,\n",
       "         'police': 3018,\n",
       "         'radio': 3963,\n",
       "         'display': 284,\n",
       "         'booths': 50,\n",
       "         'manikins': 17,\n",
       "         'pillow': 414,\n",
       "         'dress': 1845,\n",
       "         'rjm': 6,\n",
       "         'builders': 841,\n",
       "         'surgery': 2008,\n",
       "         'fees': 155,\n",
       "         'evaluation': 193,\n",
       "         'judes': 9,\n",
       "         'childrens': 1100,\n",
       "         'hospital': 4751,\n",
       "         'peter': 1073,\n",
       "         'fiverson': 1,\n",
       "         'trial': 472,\n",
       "         'lawyers': 353,\n",
       "         'inc.': 1573,\n",
       "         'pennamerica': 1,\n",
       "         'insurance': 4153,\n",
       "         'gab': 9,\n",
       "         'robbins': 98,\n",
       "         'donahue': 75,\n",
       "         'boat': 2179,\n",
       "         'marlins': 54,\n",
       "         'deal': 1065,\n",
       "         'or': 4937,\n",
       "         'no': 3988,\n",
       "         'hp': 1030,\n",
       "         'photoprinters': 5,\n",
       "         'garment': 31,\n",
       "         'rack': 483,\n",
       "         'luhrs': 5,\n",
       "         'boats': 1884,\n",
       "         'prokat': 2,\n",
       "         'prosports': 5,\n",
       "         'abbreviations': 88,\n",
       "         ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def store_word_frequency(text):\n",
    "    \"\"\"\n",
    "    Counts the frequency of each word present in the dataset\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return  \n",
    "    text = process_text(text)\n",
    "    if text: # the text might be None\n",
    "        words = text.lower().strip().split()\n",
    "        word_freq.update(dict(zip(words, [1 for _ in words])))\n",
    "    \n",
    "\n",
    "aol_data.apply(lambda row: store_word_frequency(row[\"query\"]), axis=1)\n",
    "word_freq\n",
    "# we can see here the dictionary is relatively clean (with minimal extra characters and urls...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main idea is  to take the suggestions of the spell checker \n",
    "# and choose the ones with the highest frequency in the vocabulary built out of the queries dataset\n",
    "\n",
    "def most_likely_candidate(words):\n",
    "    # sort by the frequency of the word in the vocabulary (set to 0 if the word does not appear)\n",
    "    return sorted(words, reverse=True, key=lambda x: word_freq.get(x) or 0)[0]\n",
    "def complete_user_query_with_spellchecker(query, trie, top_k=5):\n",
    "    global spell\n",
    "    query_words = query.lower().strip().split()\n",
    "    corrected_words = [most_likely_candidate(spell.candidates(word)) if len(word)> 2 else word for word in query.split()]\n",
    "    for i in range(len(corrected_words)):\n",
    "        if trie.has_subtrie(\" \".join(query_words)):\n",
    "            # in this case we proceed further to understand whether we need to modify the query or not\n",
    "            modified_query = query_words.copy()\n",
    "            modified_query[i] = corrected_words[i]\n",
    "            \n",
    "            if not trie.has_subtrie(\" \".join(modified_query)): # in case the modified query is actually not in the trie\n",
    "                continue\n",
    "        \n",
    "            node_modified = list(trie.iteritems(\" \".join(modified_query)))\n",
    "            node_original = list(trie.iteritems(\" \".join(query_words)))\n",
    "\n",
    "            if len(node_modified) < len(node_original): # the original node is sitll more likely \n",
    "                continue # keep the original \n",
    "\n",
    "        query_words[i] = corrected_words[i]\n",
    "    \n",
    "    print(\" \".join(query_words))\n",
    "    return complete_user_query(\" \".join(query_words), trie, top_k)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information retrieval\n",
      "sherlock hol\n",
      "carnegie mell\n",
      "babies r\n",
      "barbara\n"
     ]
    }
   ],
   "source": [
    "inp_queries = [\"inormation retrieval\", \"shelrock hol\", \"carnagie mell\", \"babis r\", \"Barrbara \"]\n",
    "inp_queries_corrected = [\"information retrieval\", \"sherlock hol\", \"carnegie mell\", \"babies r\", \"Barbara \"]\n",
    "\n",
    "for q, qc in zip(inp_queries, inp_queries_corrected):\n",
    "    assert  complete_user_query(qc, aol_trie, 5) == \\\n",
    "            complete_user_query_with_spellchecker(q, aol_trie, 5), \"Assert {} and {} give different results\".format(q, qc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "87916a9df29343f518d363a6149a1dfa14832b884faad311882187c1f88054e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
